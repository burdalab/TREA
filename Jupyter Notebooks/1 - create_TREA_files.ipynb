{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_secondary_file(filename,df):\n",
    "    if not os.path.exists('../Output Files/Secondary TR List'):\n",
    "        os.mkdir('../Output Files/Secondary TR List')\n",
    "    \n",
    "    df.to_csv(\"../Output Files/Secondary TR List/\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_primary_file(filename,df):\n",
    "    if not os.path.exists('../Output Files/Primary TR List'):\n",
    "        os.mkdir('../Output Files/Primary TR List')\n",
    "    \n",
    "    df.to_csv(\"../Output Files/Primary TR List/\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_TREA(filename,df):\n",
    "    if not os.path.exists('../Output Files/TR List'):\n",
    "        os.mkdir('../Output Files/TR List')\n",
    "    \n",
    "    df.to_csv(\"../Output Files/TR List/\"+filename+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logFC_mapping(df):\n",
    "    gene_to_logFC = []\n",
    "    genes = df[\"Gene.Symbol\"].unique()\n",
    "    for gene in genes:\n",
    "        try:\n",
    "            temp  = df.loc[df[\"Gene.Symbol\"] == gene]\n",
    "            gene_to_logFC.append((gene,temp[\"logFC\"].sum()/len(temp)))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return pd.DataFrame.from_records(gene_to_logFC,columns=[\"Gene.Symbol\",\"logFC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_database_df(df):\n",
    "    cleaned_data = []\n",
    "    terms = df[\"term\"].unique()\n",
    "    for term in terms:\n",
    "        try:\n",
    "            temp  = df.loc[df[\"term\"] == term]\n",
    "            cleaned_data.append((term,';'.join(temp['genes'])))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return pd.DataFrame.from_records(cleaned_data,columns=[\"term\",\"genes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_genes(df):\n",
    "    df['genes'] = df['genes'].apply(lambda x: ';'.join(list(set(x.split(';')))))\n",
    "    df['genes'] = df['genes'].apply(lambda x: x[1:] if x[0]==';' else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_database_files(disease):\n",
    "    try:\n",
    "        df_temp = pd.read_csv('../Sample Files/Chea files/Chea TR_'+disease[0]+'_Clean.csv')[['term','genes']]\n",
    "    except:\n",
    "        df_temp = pd.read_excel('../Sample Files/Chea files/Chea TR_'+disease[0]+'_Clean.xlsx')[['term','genes']]\n",
    "    df_chea = pd.DataFrame()\n",
    "    df_chea['term'] = df_temp[\"term\"].str.capitalize().str.strip()\n",
    "    df_chea['genes'] = df_temp['genes']\n",
    "    df_chea = clean_database_df(df_chea)\n",
    "    df_chea['source'] = \"Chea\"\n",
    "    \n",
    "    try:\n",
    "        df_temp = pd.read_csv('../Sample Files/ingenuity files/ingenuity TR_'+disease[0]+'_clean.csv')[['term','genes']]\n",
    "    except:\n",
    "        df_temp = pd.read_excel('../Sample Files/ingenuity files/ingenuity TR_'+disease[0]+'_clean.xlsx')[['term','genes']]\n",
    "    df_ipa = pd.DataFrame()\n",
    "    df_ipa['term'] = df_temp[\"term\"].str.capitalize().str.strip()\n",
    "    df_ipa['genes'] = df_temp['genes']\n",
    "    df_ipa = clean_database_df(df_ipa)\n",
    "    df_ipa['source'] = \"IPA\"\n",
    "    \n",
    "    if (disease[0] != \"MC\"):\n",
    "        try:\n",
    "            df_temp = pd.read_csv('../Sample Files/JASPAR-TRANSFAC files/JASPAR-TRANSFAC TR_'+disease[0]+'_Clean.csv')[['term','genes']]\n",
    "        except:\n",
    "            df_temp = pd.read_excel('../Sample Files/JASPAR-TRANSFAC files/JASPAR-TRANSFAC TR_'+disease[0]+'_Clean.xlsx')[['term','genes']]\n",
    "        df_jasper = pd.DataFrame()\n",
    "        df_jasper['term'] = df_temp[\"term\"].str.capitalize().str.strip()\n",
    "        df_jasper['genes'] = df_temp['genes']\n",
    "        df_jasper = clean_database_df(df_jasper)\n",
    "        df_jasper['source'] = \"JASPAR-TRANSFAC\"\n",
    "    else:\n",
    "        df_jasper = pd.DataFrame(columns=[\"term\",\"genes\",\"source\"])\n",
    "    return df_chea, df_ipa, df_jasper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genes(df):\n",
    "    df_deg = pd.read_csv(\"../Sample Files/DEG/\"+disease[0]+'.csv')[[\"logFC\",\"Refseq_ID\"]].rename(columns={'Refseq_ID':'term'})\n",
    "    df = df.drop(['logFC'],axis=1)\n",
    "    df[\"index1\"] = df.index\n",
    "    df = (df.set_index(['index1','term'])\n",
    "    .stack()\n",
    "    .str.split(';',expand=True)\n",
    "    .stack()\n",
    "    .unstack(-2)\n",
    "    .reset_index(-1,drop = True)\n",
    "    .reset_index()\n",
    "    .drop(\"index1\",axis = 1))\n",
    "\n",
    "    df[\"target.uniq\"] = df[\"genes\"].str.capitalize().str.strip()\n",
    "    df = df.drop(['genes','source'],axis=1)\n",
    "    df = df.merge(df_deg, how='left', left_on='target.uniq', right_on='term').drop(\"term\",axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_secondary_trs(disease,df_chea, df_ipa, df_jasper):\n",
    "    df_union = pd.concat([df_chea,df_ipa,df_jasper])\n",
    "    df_union = df_union.groupby(df_union['term']).aggregate(\";\".join)\n",
    "    df_union.reset_index(inplace=True)\n",
    "    df_union[\"term\"] = df_union[\"term\"].str.capitalize().str.strip()\n",
    "    df_deg = pd.read_csv(\"../Sample Files/DEG/\"+disease[0]+'.csv')[[\"logFC\",\"Refseq_ID\"]].rename(columns={'Refseq_ID':'term'})\n",
    "    df_deg[\"term\"] = df_deg[\"term\"].str.capitalize().str.strip()\n",
    "    return df_deg.merge(df_union, how='inner', left_on='term', right_on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_primary_trs(disease, df_chea, df_ipa, df_jasper):\n",
    "    df_ipa_chea = df_ipa.merge(df_chea, how='inner',left_on='term',right_on='term')\n",
    "    df_ipa_chea['source'] = 'Chea'\n",
    "    df_ipa_chea['genes'] = df_ipa_chea['genes_x'] +';' +df_ipa_chea['genes_y']\n",
    "    df_ipa_chea['genes'] = df_ipa_chea['genes'].apply(lambda x: ';'.join(list(set(x.split(';')))))\n",
    "    df_ipa_chea.drop(['genes_x', 'genes_y','source_y','source_x'], axis=1,inplace=True)\n",
    "    \n",
    "    df_ipa_jasper = df_ipa.merge(df_jasper, how='inner',left_on='term',right_on='term')\n",
    "    df_ipa_jasper['source'] = 'JASPAR-TRANSFAC'\n",
    "    df_ipa_jasper['genes'] = df_ipa_jasper['genes_x'] +';' +df_ipa_jasper['genes_y']\n",
    "    df_ipa_jasper.fillna('', inplace=True)\n",
    "    df_ipa_jasper['genes'] = df_ipa_jasper['genes'].apply(lambda x: ';'.join(list(set(x.split(';')))))\n",
    "    df_ipa_jasper.drop(['genes_x', 'genes_y','source_y','source_x'], axis=1,inplace=True)\n",
    "    \n",
    "    df_primary = df_ipa_jasper.merge(df_ipa_chea, how='outer',left_on='term',right_on='term')\n",
    "    df_primary.fillna('', inplace=True)\n",
    "    df_primary['IPA'] = 'IPA'\n",
    "    df_primary['source'] = df_primary[['IPA','source_x', 'source_y']].apply(lambda x: ';'.join(x), axis=1)\n",
    "    df_primary['genes'] = df_primary[['genes_x', 'genes_y']].apply(lambda x: ';'.join(x), axis=1)\n",
    "\n",
    "    return df_primary.drop(['genes_x', 'genes_y','source_y','source_x','IPA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_primary(df_primary):\n",
    "    df = df_primary[['term','source']]\n",
    "    df[\"index1\"] = df.index\n",
    "    df = (df.set_index(['index1','term'])\n",
    "    .stack()\n",
    "    .str.split(';;',expand=True)\n",
    "    .stack()\n",
    "    .unstack(-2)\n",
    "    .reset_index(-1,drop = True)\n",
    "    .reset_index()\n",
    "    .drop(\"index1\",axis=1))\n",
    "\n",
    "    df = df.groupby(df['term']).aggregate(\";\".join)\n",
    "    df.reset_index(inplace=True)\n",
    "    return (df_primary.merge(df,how='left', left_on='term', right_on='term').drop(\"source_x\",axis=1)\n",
    "            .rename(columns={'source_y':'source'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trs(disease):\n",
    "    df_chea, df_ipa, df_jasper = load_database_files(disease)\n",
    "    df_secondary = find_secondary_trs(disease,df_chea, df_ipa, df_jasper)\n",
    "    df_secondary['term'] = df_secondary['term'].str.capitalize().str.strip()\n",
    "    df_secondary.drop_duplicates(inplace=True)\n",
    "    \n",
    "    df_primary = find_primary_trs(disease,df_chea, df_ipa, df_jasper)\n",
    "    \n",
    "    df_primary = df_primary.merge(df_secondary[['term','logFC']],how='left',left_on='term',right_on='term')\n",
    "    df_primary['term'] = df_primary['term'].str.capitalize().str.strip()\n",
    "\n",
    "    df_primary.fillna(0, inplace=True)\n",
    "    df_primary['genes'] = df_primary['genes'].apply(lambda x: x[1:] if x[0]==';' else x)\n",
    "    df_primary['source'] = df_primary['source'].apply(lambda x: x[1:] if x[0]==';' else x)\n",
    "    \n",
    "    df_primary = clean_primary(df_primary)\n",
    "    df_primary = get_unique_genes(df_primary)\n",
    "    df_primary.drop_duplicates(inplace=True)\n",
    "    secondary_term = list(set(list(df_secondary['term'].unique())) - set(list(df_primary['term'].unique())))\n",
    "    \n",
    "    df_secondary = df_secondary.loc[df_secondary['term'].isin(secondary_term)]\n",
    "    df_secondary.reset_index()\n",
    "    df_secondary = get_unique_genes(df_secondary)\n",
    "    \n",
    "    return df_secondary,df_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diseases ={\n",
    "      'LPS_Cord':'LPS_Cord',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPS_Cord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for disease in diseases.items():\n",
    "    print(disease[0])\n",
    "    df_secondary,df_primary = find_trs(disease)\n",
    "    save_secondary_file(disease[1],df_secondary)\n",
    "    save_primary_file(disease[1],df_primary)\n",
    "    \n",
    "#     When Type I and II\n",
    "    save_TREA(disease[1],pd.concat([df_primary,df_secondary])[['term','genes','logFC','source']])\n",
    "    \n",
    "#     When only Type I\n",
    "#     df_secondary(Type II) is not needed for Astro-non-enriched\n",
    "#     save_TREA(disease[1],df_primary[['term','genes','logFC','source']])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
